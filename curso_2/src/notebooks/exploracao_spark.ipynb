{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark==3.3.1\n",
      "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting py4j==0.10.9.5\n",
      "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: py4j, pyspark\n",
      "\u001b[33m  DEPRECATION: pyspark is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running setup.py install for pyspark ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed py4j-0.10.9.5 pyspark-3.3.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark==3.3.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /mnt/e/alura/alura_airflow_Twitter/venv/lib/python3.9/site-packages (22.3.1)\n",
      "Collecting pip\n",
      "  Downloading pip-23.0-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 22.3.1\n",
      "    Uninstalling pip-22.3.1:\n",
      "      Successfully uninstalled pip-22.3.1\n",
      "Successfully installed pip-23.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/14 17:08:32 WARN Utils: Your hostname, cmatheus resolves to a loopback address: 127.0.1.1; using 172.28.105.128 instead (on interface eth0)\n",
      "23/02/14 17:08:32 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/14 17:08:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"twitter_transformation\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.json(\"../../data_lake/twitter_extract_dataScience\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+------------+\n",
      "|                data|            includes|                meta|extract_date|\n",
      "+--------------------+--------------------+--------------------+------------+\n",
      "|[{411419084, 1616...|{[{2011-11-13T11:...|{1616922528303435...|  2023-01-22|\n",
      "|[{137836534906265...|{[{2021-04-03T15:...|{1616922261675716...|  2023-01-22|\n",
      "|[{1264433760, 161...|{[{2013-03-13T13:...|{1616921838034030...|  2023-01-22|\n",
      "|[{156837570545650...|{[{2022-09-09T23:...|{1616921664758898...|  2023-01-22|\n",
      "|[{1264433760, 161...|{[{2013-03-13T13:...|{1616921420621021...|  2023-01-22|\n",
      "|[{1264433760, 161...|{[{2013-03-13T13:...|{1616921214621999...|  2023-01-22|\n",
      "|[{156837570545650...|{[{2022-09-09T23:...|{1616920970450673...|  2023-01-22|\n",
      "|[{1264433760, 161...|{[{2013-03-13T13:...|{1616920696248041...|  2023-01-22|\n",
      "|[{156837570545650...|{[{2022-09-09T23:...|{1616920552576278...|  2023-01-22|\n",
      "|[{137155121135112...|{[{2021-03-15T19:...|{1616920297390673...|  2023-01-22|\n",
      "+--------------------+--------------------+--------------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- data: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- author_id: string (nullable = true)\n",
      " |    |    |-- conversation_id: string (nullable = true)\n",
      " |    |    |-- created_at: string (nullable = true)\n",
      " |    |    |-- edit_history_tweet_ids: array (nullable = true)\n",
      " |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |-- id: string (nullable = true)\n",
      " |    |    |-- in_reply_to_user_id: string (nullable = true)\n",
      " |    |    |-- lang: string (nullable = true)\n",
      " |    |    |-- public_metrics: struct (nullable = true)\n",
      " |    |    |    |-- impression_count: long (nullable = true)\n",
      " |    |    |    |-- like_count: long (nullable = true)\n",
      " |    |    |    |-- quote_count: long (nullable = true)\n",
      " |    |    |    |-- reply_count: long (nullable = true)\n",
      " |    |    |    |-- retweet_count: long (nullable = true)\n",
      " |    |    |-- text: string (nullable = true)\n",
      " |-- includes: struct (nullable = true)\n",
      " |    |-- users: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- created_at: string (nullable = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |-- username: string (nullable = true)\n",
      " |-- meta: struct (nullable = true)\n",
      " |    |-- newest_id: string (nullable = true)\n",
      " |    |-- next_token: string (nullable = true)\n",
      " |    |-- oldest_id: string (nullable = true)\n",
      " |    |-- result_count: long (nullable = true)\n",
      " |-- extract_date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- col: struct (nullable = true)\n",
      " |    |-- author_id: string (nullable = true)\n",
      " |    |-- conversation_id: string (nullable = true)\n",
      " |    |-- created_at: string (nullable = true)\n",
      " |    |-- edit_history_tweet_ids: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- in_reply_to_user_id: string (nullable = true)\n",
      " |    |-- lang: string (nullable = true)\n",
      " |    |-- public_metrics: struct (nullable = true)\n",
      " |    |    |-- impression_count: long (nullable = true)\n",
      " |    |    |-- like_count: long (nullable = true)\n",
      " |    |    |-- quote_count: long (nullable = true)\n",
      " |    |    |-- reply_count: long (nullable = true)\n",
      " |    |    |-- retweet_count: long (nullable = true)\n",
      " |    |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(f.explode(\"data\")).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                 col|\n",
      "+--------------------+\n",
      "|{411419084, 16169...|\n",
      "|{9547781709805281...|\n",
      "|{1568375705456500...|\n",
      "|{1347291458278080...|\n",
      "|{8151691243222016...|\n",
      "|{411419084, 16169...|\n",
      "|{1568375705456500...|\n",
      "|{1527071629, 1616...|\n",
      "|{411419084, 16169...|\n",
      "|{1568375705456500...|\n",
      "+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(f.explode(\"data\")).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+--------------------+-------------------+----------------+----------+-----------+-----------+-------------+--------------------+\n",
      "|          author_id|    conversation_id|          created_at|                 id|impression_count|like_count|quote_count|reply_count|retweet_count|                text|\n",
      "+-------------------+-------------------+--------------------+-------------------+----------------+----------+-----------+-----------+-------------+--------------------+\n",
      "|          411419084|1616922528303435776|2023-01-21T22:15:...|1616922528303435776|               0|         0|          0|          0|            1|RT @Hackwithgibso...|\n",
      "| 954778170980528129|1616922520447221762|2023-01-21T22:15:...|1616922520447221762|               0|         0|          0|          0|           22|RT @CatherineAden...|\n",
      "|1568375705456500738|1616922500461481988|2023-01-21T22:15:...|1616922500461481988|              32|         0|          0|          0|            1|I am at your serv...|\n",
      "|1347291458278080513|1616922489564844032|2023-01-21T22:15:...|1616922489564844032|               0|         0|          0|          0|           22|RT @CatherineAden...|\n",
      "| 815169124322201600|1616922475811446784|2023-01-21T22:15:...|1616922475811446784|             180|         1|          0|          0|            0|Machine Learning ...|\n",
      "|          411419084|1616922452495577088|2023-01-21T22:15:...|1616922452495577088|               0|         0|          0|          0|            1|RT @Hackwithgibso...|\n",
      "|1568375705456500738|1616922425203073024|2023-01-21T22:15:...|1616922425203073024|               1|         0|          0|          0|            1|I am at your serv...|\n",
      "|         1527071629|1616922424074813442|2023-01-21T22:15:...|1616922424074813442|               0|         0|          0|          0|           38|RT @gp_pulipaka: ...|\n",
      "|          411419084|1616922389568458752|2023-01-21T22:15:...|1616922389568458752|               0|         0|          0|          0|            1|RT @Hackwithgibso...|\n",
      "|1568375705456500738|1616922362766671873|2023-01-21T22:15:...|1616922362766671873|               3|         0|          0|          0|            1|Contact me now fo...|\n",
      "|1378365349062656001|1616922261675716608|2023-01-21T22:14:...|1616922261675716608|               0|         0|          0|          0|          199|RT @AIPADTECH: Wh...|\n",
      "|          221916197|1616922224597819399|2023-01-21T22:14:...|1616922224597819399|               0|         0|          0|          0|           18|RT @RosanaFerrero...|\n",
      "|1223675171418099713|1616922185704132611|2023-01-21T22:14:...|1616922185704132611|               9|         0|          0|          0|            0|Believe First htt...|\n",
      "|          411419084|1616922169413603330|2023-01-21T22:14:...|1616922169413603330|               0|         0|          0|          0|            1|RT @Hackwithgibso...|\n",
      "|         2872734563|1616922150392270857|2023-01-21T22:14:...|1616922150392270857|               0|         0|          0|          0|           45|RT @mdancho84: On...|\n",
      "|1568375705456500738|1616922137641598976|2023-01-21T22:14:...|1616922137641598976|               9|         0|          0|          0|            1|Contact me now fo...|\n",
      "|1568375705456500738|1616922014089871361|2023-01-21T22:13:...|1616922014089871361|               3|         0|          0|          0|            0|For hacking or an...|\n",
      "|         2499333974|1616921922427551747|2023-01-21T22:13:...|1616921922427551747|               0|         0|          0|          0|           11|RT @gp_pulipaka: ...|\n",
      "|         1264433760|1616921873442574336|2023-01-21T22:13:...|1616921873442574336|               0|         0|          0|          0|           18|RT @Eli_Krumova: ...|\n",
      "|1448659817845850113|1616921851279872000|2023-01-21T22:13:...|1616921851279872000|               4|         0|          0|          0|            0|SQL Boot Camp 202...|\n",
      "+-------------------+-------------------+--------------------+-------------------+----------------+----------+-----------+-----------+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(f.explode(\"data\").alias(\"tweets\"))\\\n",
    ".select(\"tweets.author_id\", \"tweets.conversation_id\",\n",
    "        \"tweets.created_at\", \"tweets.id\",\n",
    "        \"tweets.public_metrics.*\", \"tweets.text\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = df.select(f.explode(\"data\").alias(\"tweets\"))\\\n",
    "  .select(\"tweets.author_id\", \"tweets.conversation_id\",\n",
    "        \"tweets.created_at\", \"tweets.id\",\n",
    "        \"tweets.public_metrics.*\", \"tweets.text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+--------------------+-------------------+----------------+----------+-----------+-----------+-------------+--------------------+\n",
      "|          author_id|    conversation_id|          created_at|                 id|impression_count|like_count|quote_count|reply_count|retweet_count|                text|\n",
      "+-------------------+-------------------+--------------------+-------------------+----------------+----------+-----------+-----------+-------------+--------------------+\n",
      "|          411419084|1616922528303435776|2023-01-21T22:15:...|1616922528303435776|               0|         0|          0|          0|            1|RT @Hackwithgibso...|\n",
      "| 954778170980528129|1616922520447221762|2023-01-21T22:15:...|1616922520447221762|               0|         0|          0|          0|           22|RT @CatherineAden...|\n",
      "|1568375705456500738|1616922500461481988|2023-01-21T22:15:...|1616922500461481988|              32|         0|          0|          0|            1|I am at your serv...|\n",
      "|1347291458278080513|1616922489564844032|2023-01-21T22:15:...|1616922489564844032|               0|         0|          0|          0|           22|RT @CatherineAden...|\n",
      "| 815169124322201600|1616922475811446784|2023-01-21T22:15:...|1616922475811446784|             180|         1|          0|          0|            0|Machine Learning ...|\n",
      "+-------------------+-------------------+--------------------+-------------------+----------------+----------+-----------+-----------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweet_df.show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dados dos usuarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                 col|\n",
      "+--------------------+\n",
      "|{2011-11-13T11:40...|\n",
      "|{2018-01-20T18:10...|\n",
      "|{2022-09-09T23:08...|\n",
      "|{2021-01-07T21:18...|\n",
      "|{2016-12-31T12:13...|\n",
      "|{2013-06-18T07:35...|\n",
      "|{2021-04-03T15:15...|\n",
      "|{2010-12-01T23:49...|\n",
      "|{2020-02-01T18:34...|\n",
      "|{2011-11-13T11:40...|\n",
      "|{2014-11-11T19:28...|\n",
      "|{2022-09-09T23:08...|\n",
      "|{2014-05-16T16:56...|\n",
      "|{2013-03-13T13:19...|\n",
      "|{2021-10-14T14:41...|\n",
      "|{2013-03-13T13:19...|\n",
      "|{2011-11-13T11:40...|\n",
      "|{2022-09-09T23:08...|\n",
      "|{2008-08-22T05:41...|\n",
      "|{2017-04-01T07:56...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(f.explode(\"includes.users\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               users|\n",
      "+--------------------+\n",
      "|{2011-11-13T11:40...|\n",
      "|{2018-01-20T18:10...|\n",
      "|{2022-09-09T23:08...|\n",
      "|{2021-01-07T21:18...|\n",
      "|{2016-12-31T12:13...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(f.explode(\"includes.users\").alias(\"users\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- username: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(f.explode(\"includes.users\").alias(\"users\")).select(\"users.*\").printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = df.select(f.explode(\"includes.users\").alias(\"users\")).select(\"users.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+--------------------+---------------+\n",
      "|          created_at|                 id|                name|       username|\n",
      "+--------------------+-------------------+--------------------+---------------+\n",
      "|2011-11-13T11:40:...|          411419084|               Rahul|  rahul05ranjan|\n",
      "|2018-01-20T18:10:...| 954778170980528129|  Fr√©d√©ric Guariento| Analogique2018|\n",
      "|2022-09-09T23:08:...|1568375705456500738|    Hack With Gibson|Hackwithgibson1|\n",
      "|2021-01-07T21:18:...|1347291458278080513|1000 Days Of Codi...|1000dayscodingb|\n",
      "|2016-12-31T12:13:...| 815169124322201600|        Data science|  Datascience__|\n",
      "|2013-06-18T07:35:...|         1527071629|         DAOUD Amine|   DAOUDAMINE88|\n",
      "|2021-04-03T15:15:...|1378365349062656001|‚öìAnaBeq.OTRL üíß| ...|  anass_forever|\n",
      "|2010-12-01T23:49:...|          221916197|        Henry Taquez|       hetaquez|\n",
      "|2020-02-01T18:34:...|1223675171418099713|    Ramsey Elbasheer| genericgranola|\n",
      "|2011-11-13T11:40:...|          411419084|               Rahul|  rahul05ranjan|\n",
      "|2014-11-11T19:28:...|         2872734563|Alii_Ibn_HassanüíØ...|       AluuneMb|\n",
      "|2022-09-09T23:08:...|1568375705456500738|    Hack With Gibson|Hackwithgibson1|\n",
      "|2014-05-16T16:56:...|         2499333974|                xql+|    ExequielMas|\n",
      "|2013-03-13T13:19:...|         1264433760|      Elitsa Krumova|    Eli_Krumova|\n",
      "|2021-10-14T14:41:...|1448659817845850113|Coupontex - Free ...|      coupontex|\n",
      "|2013-03-13T13:19:...|         1264433760|      Elitsa Krumova|    Eli_Krumova|\n",
      "|2011-11-13T11:40:...|          411419084|               Rahul|  rahul05ranjan|\n",
      "|2022-09-09T23:08:...|1568375705456500738|    Hack With Gibson|Hackwithgibson1|\n",
      "|2008-08-22T05:41:...|           15941855|        V√≠ctor Suast|    ExpresionMX|\n",
      "|2017-04-01T07:56:...| 848081553368416256|              DeepAI|       Deep__AI|\n",
      "+--------------------+-------------------+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tweet_df.coalesce(1).write.mode(\"overwrite\").json('output/tweet')\n",
    "user_df.coalesce(1).write.mode(\"overwrite\").json('output/user')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "presta aten√ß√£o nos tamanhos dos arquivos caso arquivos com uma grande massa de dados, salvar em diversos arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ef042494cb2ca06b7b6bf6ac0467470c76beb5e8766293b832cf4563df02dbb1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
